{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ddcbab-cf1b-4926-a3a2-09c73740e687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ScenarioLoader import ScenarioCollection, Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e9ec01-a6ed-4953-b050-8a70a23f1083",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Variables\n",
    "We want to simulate different leakage-scenarios. Each setting consists of a combination of \n",
    "\n",
    "- a leak position (starting from node with the ID '2' to the node with ID '32'),\n",
    "- a leak diameter (5, 10 or 15 cm).\n",
    "\n",
    "For each such setting, we define a *setting start ID*, i.e., a time point (measured in time IDs 0,1,2,3...) and a *setting end ID*. Within such time window *setting end ID* - *setting start ID*, a leak, defined by its location and size, is active, starting from a *leak start ID* and ending at the *leak end ID*. Especially, *setting start ID* $\\leq$ *leak start ID* $<$ *leak end ID* $\\leq$ *setting end ID* holds. These time IDs (not to be confused with the node IDs!) are defined in such a way, that the settings' timewindow can be a chosen number *length setting* = *setting end ID* - *setting start ID* and that the total number of samples (over all settings) where any leak is activate is approximately as large as the number of samples where there is no leak active in the WDN at all.\n",
    "\n",
    "Moreover, we put different node IDs, i.e., leak locations into *groups*. Later on, we want to find out how the models we work with behave on such different groups. (We could also define a group per node ID, corresponding to a leak position, but this would not scale with larger WDNs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d44832a-19cf-4f6f-91f7-66fbbcc49924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- setting definition\n",
    "# define node IDs for nodes on which we want to simulate leaks\n",
    "nodes = [str(x+1) for x in range(1,32)] \n",
    "# define diameters (in cm) the leaks should have (without duplicates)\n",
    "diameters = [15, 5, 10]\n",
    "# define length of each setting\n",
    "length_setting = 1440 # ten days if delta = 10min = 600s\n",
    "\n",
    "# --- group definition\n",
    "# node IDs groups\n",
    "group1 = ['23', '24', '25', '28', '29', '30', '31', '32']\n",
    "group2 = ['2', '3', '14', '15', '16', '17', '18', '19', '20', '21', '22', '26', '27'] # evtl. put 26 to group 1\n",
    "group3 = ['4', '5', '6', '7', '8', '9', '10', '11', '12', '13'] # evtl. put 4 and 5 to group 2\n",
    "\n",
    "# generate helpful dictionary to access group information quickly\n",
    "groups_values = [group1, group2, group3]\n",
    "groups_keys = ['group' + str(i+1) for i in range(len(groups_values))]\n",
    "groups_per_group = dict(zip(groups_keys, groups_values))\n",
    "groups_per_node = dict()\n",
    "for node in nodes:\n",
    "    for group in groups_per_group:\n",
    "        if node in groups_per_group[group]:\n",
    "            groups_per_node[node] = group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5cc056-91f3-4170-b2e8-7be520713962",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Label generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d154217-5ba1-491e-a8b3-a581e902bf98",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def LeakInformation(nodes,\n",
    "                    diameters,\n",
    "                    length_setting,\n",
    "                    groups_per_node,\n",
    "                    option=3,\n",
    "                    offset=0,\n",
    "                    print_info=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    nodes:               list of node IDs for nodes on which leak should be simulated\n",
    "    diameters:           list of diameters the leaks should have\n",
    "    length_settings:     integer corresponding to the length of each setting\n",
    "    groups_per_node:     dictionary with keys=node ID, value=group name\n",
    "    option:              integer, 1 - leak appears in the middle of each setting\n",
    "                                  2 - leak appears at the start of each setting\n",
    "                                  3 - leak appears at the start of each setting,\n",
    "                                      first setting is not taken into account \n",
    "                                      for balanced label creation\n",
    "    offset:              an offset that in the end will be added on top of each time ID\n",
    "                         (this is useful if a time window before the actual time series\n",
    "                          is required for, e.g., preprocessing)\n",
    "    print info:          boolean for whether intermediate results should be printed\n",
    "    \"\"\"\n",
    "    \n",
    "    # ----- leak information in data frame style\n",
    "    # --- initialize data frame\n",
    "    # generate setting numbers (each combination of node ID and diameter)\n",
    "    nb_settings = len(nodes) * len(diameters)\n",
    "    settings = [idx+1 for idx in range(0,nb_settings)]\n",
    "    # generate diameters (in cm) the leaks should have (with duplicates)\n",
    "    diameters_old = diameters.copy()\n",
    "    diameters = list()\n",
    "    for diameter in diameters_old:\n",
    "        diameters += [diameter] * len(nodes) \n",
    "    # generate placehoders\n",
    "    groups = [np.nan for _ in range(0,nb_settings)]\n",
    "    setting_start = groups.copy()\n",
    "    leak_start = groups.copy()\n",
    "    leak_end = groups.copy()\n",
    "    setting_end = groups.copy()\n",
    "    \n",
    "    data = {'group': groups,\n",
    "            'node ID': nodes * len(diameters_old), \n",
    "            'diameter': diameters, \n",
    "            'setting start ID': setting_start,\n",
    "            'leak start ID': leak_start, \n",
    "            'leak end ID': leak_end,\n",
    "            'setting end ID': setting_end}\n",
    "    df = pd.DataFrame(data=data, index=settings)\n",
    "    \n",
    "    # --- fill data frame\n",
    "    # some computations which will assure that |{Y=0}| approx. |{Y=1}| holds\n",
    "    n = length_setting\n",
    "    K = nb_settings\n",
    "    rd = round( ( (K + 1) * n + 1 ) / (2 * K) )\n",
    "    \n",
    "    if print_info:\n",
    "        print('Nb. of settings with leak: {}'.format(K))\n",
    "        print('Length of each setting: {} (= {} d)'.format(n, \n",
    "                                                           n*600/60/60/24))\n",
    "        print('rd: {}'.format(rd))\n",
    "        \n",
    "     # OPTION 1\n",
    "    if option==1:\n",
    "        i_s = int((n-rd)/2)\n",
    "        i_e = int((n+rd)/2)\n",
    "        for idx in df.index:\n",
    "            # access group of node\n",
    "            node_id = df.loc[idx, 'node ID']\n",
    "            df.loc[idx, 'group'] = groups_per_node[node_id]\n",
    "            # calculate time IDs\n",
    "            df.loc[idx, 'setting start ID'] = idx*n + 1\n",
    "            df.loc[idx, 'leak start ID'] = idx*n + 1 + i_s\n",
    "            df.loc[idx, 'leak end ID'] = idx*n + 1 + i_e\n",
    "            df.loc[idx, 'setting end ID'] = (idx+1)*n\n",
    "\n",
    "        # information for double check\n",
    "        setting_0 = (n - 1 + 1) - ((1 + i_e - 1) - (1 + i_s) + 1)\n",
    "        setting_1 = (1 + i_e - 1) - (1 + i_s) + 1\n",
    "        total_0 = (n + 1) + K * setting_0\n",
    "        total_1 = K * setting_1\n",
    "\n",
    "    # OPTION 2\n",
    "    if option==2:\n",
    "        i_s = 0\n",
    "        i_e = rd\n",
    "        for idx in df.index:\n",
    "            # access group of node\n",
    "            node_id = df.loc[idx, 'node ID']\n",
    "            df.loc[idx, 'group'] = groups_per_node[node_id]\n",
    "            # calculate time IDs\n",
    "            df.loc[idx, 'setting start ID'] = idx*n + 1\n",
    "            df.loc[idx, 'leak start ID'] = idx*n + 1 + i_s\n",
    "            df.loc[idx, 'leak end ID'] = idx*n + 1 + i_e\n",
    "            df.loc[idx, 'setting end ID'] = (idx+1)*n\n",
    "\n",
    "        # information for double check\n",
    "        setting_0 = n - (1 + i_e) + 1 \n",
    "        setting_1 = (1 + i_e - 1) - 1 + 1 \n",
    "        total_0 = (n + 1) + K * setting_0\n",
    "        total_1 = K * setting_1\n",
    "        \n",
    "    # OPTION 3\n",
    "    if option==3:\n",
    "        i_s = 0\n",
    "        i_e = int(n/2)\n",
    "        for idx in df.index:\n",
    "            # access group of node\n",
    "            node_id = df.loc[idx, 'node ID']\n",
    "            df.loc[idx, 'group'] = groups_per_node[node_id]\n",
    "            # calculate time IDs\n",
    "            df.loc[idx, 'setting start ID'] = idx*n + 1\n",
    "            df.loc[idx, 'leak start ID'] = idx*n + 1 + i_s\n",
    "            df.loc[idx, 'leak end ID'] = idx*n + 1 + i_e\n",
    "            df.loc[idx, 'setting end ID'] = (idx+1)*n\n",
    "\n",
    "        # information for double check\n",
    "        setting_0 = n - (1 + i_e) + 1 \n",
    "        setting_1 = (1 + i_e - 1) - 1 + 1 \n",
    "        total_0 = K * setting_0\n",
    "        total_1 = K * setting_1\n",
    "        \n",
    "    # compute offset\n",
    "    col_filter = ['setting start ID', 'leak start ID', 'leak end ID', 'setting end ID']\n",
    "    df.loc[:, col_filter] = df.loc[:, col_filter] + offset\n",
    "    \n",
    "    # double check\n",
    "    df['Y = 0 on ride side'] = (df['leak start ID'] - 1) - df['setting start ID'] + 1\n",
    "    df['Y = 1'] = (df['leak end ID'] - 1) - df['leak start ID'] + 1\n",
    "    df['Y = 0 on left side'] = df['setting end ID'] - df['leak end ID'] + 1\n",
    "    df['Y = 0'] = df['Y = 0 on ride side'] + df['Y = 0 on left side']\n",
    "\n",
    "    if print_info:\n",
    "        print('\\n')    \n",
    "        print('i_e: {}'.format(i_e))\n",
    "        print('i_e - i_s: {}'.format(i_e - i_s))\n",
    "        print('Expected samples Y = 0 per setting: {}'.format(setting_0))\n",
    "        print('Expected samples Y = 1 per setting: {}'.format(setting_1))\n",
    "        print('Expected samples Y = 0 in total: {}'.format(total_0))\n",
    "        print('Expected samples Y = 1 in total: {}'.format(total_1))\n",
    "        print('Expected samples in total: {}'.format(total_0+total_1))\n",
    "        print('\\nNote that there are some rounding errors, find exact results by removing round() and int() in the code.')\n",
    "    \n",
    "    df_leak_information = df.copy()\n",
    "    \n",
    "    # ----- leak information in dictionary style\n",
    "    leak_information = dict()\n",
    "    for idx in df.index:\n",
    "        information = dict()\n",
    "        information['group'] = df.loc[idx, 'group']\n",
    "        information['diameter'] = df.loc[idx, 'diameter']\n",
    "        information['leak start ID'] = df.loc[idx, 'leak start ID']\n",
    "        information['leak end ID'] = df.loc[idx, 'leak end ID']\n",
    "\n",
    "        node_id = df.loc[idx, 'node ID']\n",
    "        if node_id not in leak_information.keys():\n",
    "            leak_information[node_id] = dict()\n",
    "            leak_information[node_id]['1'] = information\n",
    "        else: \n",
    "            nb_leaks = len(leak_information[node_id])\n",
    "            leak_information[node_id][str(nb_leaks + 1)] = information\n",
    "\n",
    "    return df_leak_information, leak_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c60f49-5f9d-43ea-9539-16cb310a9984",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GenerateLabels(nodes,\n",
    "                   df_leak_information,\n",
    "                   leak_information,\n",
    "                   length_setting,\n",
    "                   groups_values,\n",
    "                   offset=0,\n",
    "                   print_info=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    nodes:               list of node IDs for nodes on which leak should be simulated\n",
    "    df_leak_information: data frame, first output from LeakInformation()\n",
    "    leak_information:    dictionary, second output from LeakInformation()\n",
    "    groups_values:       list of lists of all groups\n",
    "    length_settings:     integer corresponding to the length of each setting\n",
    "    groups_per_node:     dictionary with keys=node ID, value=group name\n",
    "    offset:              an offset that in the end will be added on top of each time ID\n",
    "                         (this is useful if a time window before the actual time series\n",
    "                          is required for, e.g., preprocessing)\n",
    "    print info:          boolean for whether intermediate results should be printed\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_settings = len(df_leak_information.index)\n",
    "    # nb_settings + 1 setting for a setting with no leak at all\n",
    "    nb_samples_incl_offset = (nb_settings + 1) * length_setting + offset + 1\n",
    "    if print_info == True:\n",
    "        print('Nb. of samples inclusive offset: {}'.format(nb_samples_incl_offset))\n",
    "      \n",
    "    # --- initialize labels\n",
    "    y = np.empty(nb_samples_incl_offset)\n",
    "    y_values = [y.copy() for _ in range(len(groups_values))]\n",
    "    y_keys = ['group' + str(i+1) for i in range(len(groups_values))]\n",
    "    y_per_group = dict(zip(y_keys, y_values))\n",
    "\n",
    "    # --- compute labels\n",
    "    for i in range(len(y)):\n",
    "        # usage of this boolean makes code faster, but not necessarily needed\n",
    "        leak_found = False\n",
    "        \n",
    "        for node_id in nodes:\n",
    "            \n",
    "            for leak in leak_information[node_id]:\n",
    "\n",
    "                if leak_found == False:\n",
    "                \n",
    "                    # for each time ID i, check whether this time ID \n",
    "                    # lies between some leak start ID and some leak end ID\n",
    "                    start_id = leak_information[node_id][leak]['leak start ID']\n",
    "                    end_id = leak_information[node_id][leak]['leak end ID']\n",
    "                    if (start_id <= i) and (i < end_id):\n",
    "                        y[i] = 1\n",
    "                        group = leak_information[node_id][leak]['group']\n",
    "                        y_per_group[group][i] = 1\n",
    "    \n",
    "                        leak_found = True\n",
    "    \n",
    "    # transform numpy array to pandas series\n",
    "    y = pd.Series(y)\n",
    "    for group in y_per_group:\n",
    "        y_per_group[group] = pd.Series(y_per_group[group])\n",
    "        \n",
    "    return y, y_per_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a086c2-debd-4263-b45b-17df213dd762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- generate leak information\n",
    "df_leak_information, leak_information = LeakInformation(nodes=nodes, \n",
    "                                                        diameters=diameters, \n",
    "                                                        length_setting=length_setting,\n",
    "                                                        groups_per_node=groups_per_node,\n",
    "                                                        option=2,\n",
    "                                                        offset=100,\n",
    "                                                        print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af00f35-f74f-4c4e-bda4-272dacdf1ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leak_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0ceeff-f8e7-4798-a4b1-8f1abd9084f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- generate labels based on leak information\n",
    "start = time.time()\n",
    "y, y_per_group = GenerateLabels(nodes=nodes,\n",
    "                                df_leak_information=df_leak_information,\n",
    "                                leak_information=leak_information,\n",
    "                                length_setting=length_setting,\n",
    "                                groups_values=groups_values,\n",
    "                                offset=100)\n",
    "y_noleaks = np.zeros(len(y))\n",
    "end = time.time()\n",
    "print('Time needed: {}'.format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145472be-cdf9-4762-93c6-9e2ab8b9625e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f78dd2c-1c76-483e-93eb-e83dff4b80b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- generate features\n",
    "# initialize scenario collection\n",
    "collection = ScenarioCollection('../1_FeatureGeneration/scenarios')\n",
    "\n",
    "# list scenarios and configs of interest\n",
    "scenarios = collection.list_scenarios()\n",
    "scenarios.sort()\n",
    "scenario = scenarios[0]\n",
    "print('Scenarios:', scenarios)\n",
    "print('Configs:', collection.list_configs(scenario))\n",
    "print('\\n') \n",
    "\n",
    "# load data\n",
    "sensor_config = collection.list_configs(scenario)['SensorConfigs'][0]\n",
    "sensorfault_config = collection.list_configs(scenario)['SensorfaultConfigs'][0]\n",
    "leak_config_leaks = collection.list_configs(scenario)['LeakConfigs'][0]\n",
    "leak_config_noleaks = collection.list_configs(scenario)['LeakConfigs'][-1]\n",
    "print('Scenario:', scenario)\n",
    "print('Sensor config:', sensor_config)\n",
    "print('Sensor fault config:', sensorfault_config)\n",
    "print('Leak config \"Leaks\":', leak_config_leaks)\n",
    "print('Leak config \"NoLeaks\":', leak_config_noleaks)\n",
    "\n",
    "df_leaks = collection.get(scenario, leak_config_leaks, sensor_config, sensorfault_config)\n",
    "df_noleaks = collection.get(scenario, leak_config_noleaks, sensor_config, sensorfault_config)\n",
    "df_leaks = df_leaks['pressure'].reset_index().drop('time', axis=1)\n",
    "df_noleaks = df_noleaks['pressure'].reset_index().drop('time', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651db4eb-1d6e-4fda-a7ef-3098bf6e42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4941bf3-a276-4dab-95bf-cafe11abf0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noleaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501ca745-dd15-4e2a-9691-d9bf59329e54",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a25ba2d-cf70-4889-ac7b-759c7dc9ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- add labels to features\n",
    "for group in y_per_group:\n",
    "    df_leaks['y_' + group] = y_per_group[group]\n",
    "    df_noleaks['y_' + group] = y_noleaks\n",
    "df_leaks['y'] = y\n",
    "df_noleaks['y'] = y_noleaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d4ad6-89e6-4779-ae5a-11c0f3d027d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9819c3-4198-4a03-b68d-394aca3fc597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noleaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6014f7e7-3cd5-4752-8870-41f1ed69878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leak_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219fac7c-2015-4d49-8e8c-e836e7137145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- store data\n",
    "df_leaks.to_excel('data_leaks.xlsx',\n",
    "                  sheet_name='leaks')\n",
    "df_noleaks.to_excel('data_noleaks.xlsx',\n",
    "                   sheet_name='noleaks')\n",
    "\n",
    "# --- store leak information\n",
    "df_leak_information.to_excel('information_leaks.xlsx',\n",
    "                             sheet_name='information')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
